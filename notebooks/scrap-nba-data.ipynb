{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 2007\n",
    "end = 2007\n",
    "\n",
    "end += 1\n",
    "\n",
    "seasons_list = [year for year in range(start, end)]\n",
    "seasons_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_names(season):\n",
    "    if season == 2013:\n",
    "        team_names = {\n",
    "        'ATL': 'Atlanta Hawks',\n",
    "        'BOS': 'Boston Celtics',\n",
    "        'BRK': 'Brooklyn Nets',\n",
    "        'CHA': 'Charlotte Bobcats',\n",
    "        'CHI': 'Chicago Bulls',\n",
    "        'CLE': 'Cleveland Cavaliers',\n",
    "        'DAL': 'Dallas Mavericks',\n",
    "        'DEN': 'Denver Nuggets',\n",
    "        'DET': 'Detroit Pistons',\n",
    "        'GSW': 'Golden State Warriors',\n",
    "        'HOU': 'Houston Rockets',\n",
    "        'IND': 'Indiana Pacers',\n",
    "        'LAC': 'Los Angeles Clippers',\n",
    "        'LAL': 'Los Angeles Lakers',\n",
    "        'MEM': 'Memphis Grizzlies',\n",
    "        'MIA': 'Miami Heat',\n",
    "        'MIL': 'Milwaukee Bucks',\n",
    "        'MIN': 'Minnesota Timberwolves',\n",
    "        'NOH': 'New Orleans Hornets',\n",
    "        'NYK': 'New York Knicks',\n",
    "        'OKC': 'Oklahoma City Thunder',\n",
    "        'ORL': 'Orlando Magic',\n",
    "        'PHI': 'Philadelphia 76ers',\n",
    "        'PHO': 'Phoenix Suns',\n",
    "        'POR': 'Portland Trail Blazers',\n",
    "        'SAC': 'Sacramento Kings',\n",
    "        'SAS': 'San Antonio Spurs',\n",
    "        'TOR': 'Toronto Raptors',\n",
    "        'UTA': 'Utah Jazz',\n",
    "        'WAS': 'Washington Wizards'\n",
    "    }\n",
    "    elif season == 2014:\n",
    "        team_names = {\n",
    "            'ATL': 'Atlanta Hawks',\n",
    "            'BOS': 'Boston Celtics',\n",
    "            'BRK': 'Brooklyn Nets',\n",
    "            'CHA': 'Charlotte Bobcats',\n",
    "            'CHI': 'Chicago Bulls',\n",
    "            'CLE': 'Cleveland Cavaliers',\n",
    "            'DAL': 'Dallas Mavericks',\n",
    "            'DEN': 'Denver Nuggets',\n",
    "            'DET': 'Detroit Pistons',\n",
    "            'GSW': 'Golden State Warriors',\n",
    "            'HOU': 'Houston Rockets',\n",
    "            'IND': 'Indiana Pacers',\n",
    "            'LAC': 'Los Angeles Clippers',\n",
    "            'LAL': 'Los Angeles Lakers',\n",
    "            'MEM': 'Memphis Grizzlies',\n",
    "            'MIA': 'Miami Heat',\n",
    "            'MIL': 'Milwaukee Bucks',\n",
    "            'MIN': 'Minnesota Timberwolves',\n",
    "            'NOP': 'New Orleans Pelicans',\n",
    "            'NYK': 'New York Knicks',\n",
    "            'OKC': 'Oklahoma City Thunder',\n",
    "            'ORL': 'Orlando Magic',\n",
    "            'PHI': 'Philadelphia 76ers',\n",
    "            'PHO': 'Phoenix Suns',\n",
    "            'POR': 'Portland Trail Blazers',\n",
    "            'SAC': 'Sacramento Kings',\n",
    "            'SAS': 'San Antonio Spurs',\n",
    "            'TOR': 'Toronto Raptors',\n",
    "            'UTA': 'Utah Jazz',\n",
    "            'WAS': 'Washington Wizards'\n",
    "        }\n",
    "    elif season < 2013:\n",
    "        team_names = {\n",
    "            'ATL': 'Atlanta Hawks',\n",
    "            'BOS': 'Boston Celtics',\n",
    "            'NJN': 'New Jersey Nets',\n",
    "            'CHA': 'Charlotte Bobcats',\n",
    "            'CHI': 'Chicago Bulls',\n",
    "            'CLE': 'Cleveland Cavaliers',\n",
    "            'DAL': 'Dallas Mavericks',\n",
    "            'DEN': 'Denver Nuggets',\n",
    "            'DET': 'Detroit Pistons',\n",
    "            'GSW': 'Golden State Warriors',\n",
    "            'HOU': 'Houston Rockets',\n",
    "            'IND': 'Indiana Pacers',\n",
    "            'LAC': 'Los Angeles Clippers',\n",
    "            'LAL': 'Los Angeles Lakers',\n",
    "            'MEM': 'Memphis Grizzlies',\n",
    "            'MIA': 'Miami Heat',\n",
    "            'MIL': 'Milwaukee Bucks',\n",
    "            'MIN': 'Minnesota Timberwolves',\n",
    "            'NOH': 'New Orleans Hornets',\n",
    "            'NYK': 'New York Knicks',\n",
    "            'OKC': 'Oklahoma City Thunder',\n",
    "            'ORL': 'Orlando Magic',\n",
    "            'PHI': 'Philadelphia 76ers',\n",
    "            'PHO': 'Phoenix Suns',\n",
    "            'POR': 'Portland Trail Blazers',\n",
    "            'SAC': 'Sacramento Kings',\n",
    "            'SAS': 'San Antonio Spurs',\n",
    "            'TOR': 'Toronto Raptors',\n",
    "            'UTA': 'Utah Jazz',\n",
    "            'WAS': 'Washington Wizards'\n",
    "        }\n",
    "    else:\n",
    "        team_names = {\n",
    "        'ATL': 'Atlanta Hawks',\n",
    "        'BOS': 'Boston Celtics',\n",
    "        'BRK': 'Brooklyn Nets',\n",
    "        'CHO': 'Charlotte Hornets',\n",
    "        'CHI': 'Chicago Bulls',\n",
    "        'CLE': 'Cleveland Cavaliers',\n",
    "        'DAL': 'Dallas Mavericks',\n",
    "        'DEN': 'Denver Nuggets',\n",
    "        'DET': 'Detroit Pistons',\n",
    "        'GSW': 'Golden State Warriors',\n",
    "        'HOU': 'Houston Rockets',\n",
    "        'IND': 'Indiana Pacers',\n",
    "        'LAC': 'Los Angeles Clippers',\n",
    "        'LAL': 'Los Angeles Lakers',\n",
    "        'MEM': 'Memphis Grizzlies',\n",
    "        'MIA': 'Miami Heat',\n",
    "        'MIL': 'Milwaukee Bucks',\n",
    "        'MIN': 'Minnesota Timberwolves',\n",
    "        'NOP': 'New Orleans Pelicans',\n",
    "        'NYK': 'New York Knicks',\n",
    "        'OKC': 'Oklahoma City Thunder',\n",
    "        'ORL': 'Orlando Magic',\n",
    "        'PHI': 'Philadelphia 76ers',\n",
    "        'PHO': 'Phoenix Suns',\n",
    "        'POR': 'Portland Trail Blazers',\n",
    "        'SAC': 'Sacramento Kings',\n",
    "        'SAS': 'San Antonio Spurs',\n",
    "        'TOR': 'Toronto Raptors',\n",
    "        'UTA': 'Utah Jazz',\n",
    "        'WAS': 'Washington Wizards'\n",
    "    }\n",
    "    return team_names\n",
    "\n",
    "team_names = get_team_names(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_conferences = {\n",
    "    'ATL': 'EAST',\n",
    "    'BOS': 'EAST',\n",
    "    'BRK': 'EAST',\n",
    "    'NJN': 'EAST',\n",
    "    'CHA': 'EAST',\n",
    "    'CHO': 'EAST',\n",
    "    'CHI': 'EAST',\n",
    "    'CLE': 'EAST',\n",
    "    'DAL': 'WEST',\n",
    "    'DEN': 'WEST',\n",
    "    'DET': 'EAST',\n",
    "    'GSW': 'WEST',\n",
    "    'HOU': 'WEST',\n",
    "    'IND': 'EAST',\n",
    "    'LAC': 'WEST',\n",
    "    'LAL': 'WEST',\n",
    "    'MEM': 'WEST',\n",
    "    'MIA': 'EAST',\n",
    "    'MIL': 'EAST',\n",
    "    'MIN': 'WEST',\n",
    "    'NOP': 'WEST',\n",
    "    'NOH': 'WEST',\n",
    "    'NYK': 'EAST',\n",
    "    'OKC': 'WEST',\n",
    "    'ORL': 'EAST',\n",
    "    'PHI': 'EAST',\n",
    "    'PHO': 'WEST',\n",
    "    'POR': 'WEST',\n",
    "    'SAC': 'WEST',\n",
    "    'SAS': 'WEST',\n",
    "    'TOR': 'EAST',\n",
    "    'UTA': 'WEST',\n",
    "    'WAS': 'EAST'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# team_names = {\n",
    "#     # 'DET': 'Detroit Pistons',\n",
    "#     # 'BOS': 'Boston Celtics',\n",
    "#     # 'PHO': 'Phoenix Suns',\n",
    "#     'MEM': 'Memphis Grizzlies',\n",
    "\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Roster Average Stats Per Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert height to inches (Ht format 'ft-in' to inches)\n",
    "def height_to_inches(height):\n",
    "    if pd.isna(height):\n",
    "        return None\n",
    "    feet, inches = map(int, height.split('-'))\n",
    "    return feet * 12 + inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_roster(roster, team,team_names):\n",
    "\n",
    "    roster['ht'] = roster['Ht'].apply(height_to_inches)\n",
    "    \n",
    "    roster['birth_year'] = pd.to_datetime(roster['Birth Date']).dt.year\n",
    "\n",
    "    roster['age'] = roster['Season']- roster['birth_year'] -1\n",
    "\n",
    "    roster['exp'] = roster['Exp'].replace('R', 0)\n",
    "\n",
    "    roster['exp'] = roster['exp'].round().astype(int)\n",
    "\n",
    "    roster['team'] = team\n",
    "\n",
    "    roster['team_full_name'] = roster['team'].map(team_names)\n",
    "    \n",
    "    roster.drop(columns=['College','No.','Player','Pos','Birth Date','Birth','birth_year'], inplace=True)\n",
    "\n",
    "    return roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.basketball-reference.com/teams/DAL/2025.html\n",
    "\n",
    "def scrape_roster(season):\n",
    "    all_data = pd.DataFrame()\n",
    "    team_names = get_team_names(season)\n",
    "\n",
    "    for team in team_names:\n",
    "\n",
    "        url = f\"https://www.basketball-reference.com/teams/{team}/{season}.html\"\n",
    "\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # print(response)\n",
    "        # print(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            table = soup.find('table', {'id': 'roster'})\n",
    "\n",
    "            if table:\n",
    "                df = pd.read_html(io.StringIO(str(table)))[0]\n",
    "\n",
    "                df['Season'] = season\n",
    "                \n",
    "                df = clean_roster(df,team,team_names)\n",
    "\n",
    "                all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "            else:\n",
    "                print(f\"No table found for {season}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data for {season}\")\n",
    "\n",
    "        time.sleep(4)\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape_roster(2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_avg_roster(roster):\n",
    "    avg_roster = roster.groupby(['team', 'team_full_name','Season']).agg(\n",
    "        avg_age=('age', 'mean'),\n",
    "        avg_exp=('exp', 'mean'),\n",
    "        avg_weight=('Wt', 'mean'),\n",
    "        avg_height=('ht', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    avg_roster = avg_roster[['Season','team', 'team_full_name', 'avg_age', 'avg_exp', 'avg_weight', 'avg_height']]\n",
    "    \n",
    "    return avg_roster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append pre-season odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.basketball-reference.com/leagues/NBA_2025_preseason_odds.html\n",
    "\n",
    "def scrape_preseason_odds(season):\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_preseason_odds.html\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # print(response)\n",
    "    # print(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table = soup.find('table', {'id': 'NBA_preseason_odds'})\n",
    "\n",
    "        if table:\n",
    "            df = pd.read_html(io.StringIO(str(table)))[0]\n",
    "\n",
    "            all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "        else:\n",
    "        \n",
    "            print(f\"No table found for {season}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {season}\")\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preseason_odds = scrape_preseason_odds(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_n_odds = pd.merge(avg_roster, preseason_odds, left_on='team_full_name', right_on='Team', how='left')\n",
    "\n",
    "avg_n_odds.drop(columns='Team', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_n_odds.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append salary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_salaries(salaries):\n",
    "    \n",
    "    salaries = salaries.head(25).copy()\n",
    "\n",
    "    salaries.rename(columns={\"Unnamed: 1\":\"player_name\"}, inplace=True)\n",
    "    \n",
    "    salaries.loc[:, 'Salary'] = salaries['Salary'].fillna(0)\n",
    "\n",
    "    salaries.loc[:, 'Salary'] = salaries['Salary'].replace({r'\\$': '', ',': ''}, regex=True).astype(int)\n",
    "\n",
    "    salaries = salaries.sort_values(by='Salary', ascending=False)\n",
    "\n",
    "    salaries = salaries.drop(columns=['Rk'])\n",
    "\n",
    "    return salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.basketball-reference.com/teams/CHO/2025.html\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def scrape_salaries(\n",
    "        season,\n",
    "        driver,\n",
    "    ):\n",
    "\n",
    "    all_data = pd.DataFrame()\n",
    "    team_names = get_team_names(season)\n",
    "    \n",
    "    for team in team_names:\n",
    "\n",
    "        url = f\"https://www.basketball-reference.com/teams/{team}/{season}.html\"\n",
    "\n",
    "        driver.get(url)\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        div = soup.find('div', {'id': 'div_salaries2'})\n",
    "        \n",
    "        if div:\n",
    "            table = div.find('table', {'id': 'salaries2'})\n",
    "            if table:\n",
    "                df = pd.read_html(io.StringIO(str(table)))[0]\n",
    "                df['Season'] = season\n",
    "                df['team']= team\n",
    "                df = clean_salaries(df)\n",
    "                all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "            else:\n",
    "                print(f\"No table found inside the div for {team} in {season}\")\n",
    "        else:\n",
    "            print(f\"No div with id 'div_salaries2' found for {team} in {season}\")\n",
    "            \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() \n",
    "\n",
    "salaries = scrape_salaries(\n",
    "    2024, \n",
    "    driver,\n",
    ")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the number of top players per team per season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_top_players(salaries,threshold=20):\n",
    "    # based on the teams salaries we are trying to identify the numbers of stars/top players on the team (a good example is the Phoenix Suns in 2025)\n",
    "\n",
    "    above = salaries[salaries['salary_percentage'] > threshold].shape[0]\n",
    "    below = salaries[salaries['salary_percentage'] <= threshold].shape[0]\n",
    "    \n",
    "    return pd.Series({'top_players': above, 'not_top_players': below})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_players(salaries):\n",
    "    total_salary = salaries.groupby(['team', 'Season'])['Salary'].sum().reset_index(name='total_salary')\n",
    "\n",
    "    salaries = salaries.merge(total_salary, on=['team', 'Season'], how='left')\n",
    "\n",
    "    salaries['salary_percentage'] = (salaries['Salary'] / salaries['total_salary']) * 100\n",
    "\n",
    "    top_players = salaries.groupby(['team', 'Season']).apply(count_top_players).reset_index()\n",
    "    \n",
    "    return top_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries[salaries['team']=='LAL'].sort_values('salary_percentage', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_salary_stats = salaries.groupby(['team', 'Season']).agg(\n",
    "    highest_salary=('Salary', 'max'),\n",
    "    median_salary=('Salary', 'median'),\n",
    "    total_salary=('Salary', 'sum'),\n",
    "    \n",
    ").reset_index()\n",
    "\n",
    "top_players = find_top_players(salaries)\n",
    "\n",
    "team_salary_stats = pd.merge(team_salary_stats, top_players, on=['team', 'Season'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_salary_stats.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_odds_salary_players = pd.merge(avg_n_odds, team_salary_stats,on=['team', 'Season'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_odds_salary_players.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_odds_salary_players.to_csv('data/2025_team_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append Franchise History/Championship stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_champions(df):\n",
    "\n",
    "    nba_champions = df[[('Unnamed: 0_level_0', 'Year'), ('Finals', 'Champion')]]\n",
    "    nba_champions.columns = ['Year', 'Champion']\n",
    "\n",
    "    nba_champions = nba_champions[nba_champions.Year.notna()]\n",
    "\n",
    "    nba_champions.Year = nba_champions.Year.astype(int)\n",
    "\n",
    "    return nba_champions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.basketball-reference.com/playoffs/\n",
    "\n",
    "def scrape_champions():\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    url = f\"https://www.basketball-reference.com/playoffs/\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # print(response)\n",
    "    # print(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table = soup.find('table', {'id': 'champions_index'})\n",
    "\n",
    "        if table:\n",
    "            df = pd.read_html(io.StringIO(str(table)))[0]\n",
    "            df = clean_champions(df)\n",
    "        else:\n",
    "        \n",
    "            print(f\"No table found \")\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data \")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of championships for a given team and season\n",
    "\n",
    "def nb_championships(season):\n",
    "\n",
    "    team_names = get_team_names(season)\n",
    "    \n",
    "    nba_champions = scrape_champions()\n",
    "\n",
    "    rev_team_names = {v: k for k, v in team_names.items()}\n",
    "\n",
    "    nba_champions['team'] = nba_champions['Champion'].map(rev_team_names)\n",
    "    \n",
    "    team_championships = []\n",
    "    \n",
    "    for team in team_names:\n",
    "        nb_total = len(nba_champions[\n",
    "            (nba_champions['team'] == team) & \n",
    "            (nba_champions['Year'] <= season)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        nb_interval = len(nba_champions[\n",
    "            (nba_champions['team'] == team) & \n",
    "            (nba_champions['Year'] <= season) & \n",
    "            (nba_champions['Year'] > season-4)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        team_championships.append({\n",
    "            'team': team,\n",
    "            'Season': season,\n",
    "            'nb_championships': nb_total,\n",
    "            'nb_champ_past_4y': nb_interval,\n",
    "            'winner': len(nba_champions[\n",
    "                (nba_champions['team'] == team) & \n",
    "                (nba_champions['Year'] == season)\n",
    "                ]\n",
    "            ),\n",
    "\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(team_championships)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_championships(2020).sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_championships = nb_championships(team_names,2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_odds_salary_players_champ = avg_odds_salary_players.merge(team_championships, on=['team', 'Season'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_odds_salary_players_champ.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append ranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ranking(df):\n",
    "    df = df.sort_values(by='W/L%', ascending=False)\n",
    "    \n",
    "    df.rename(columns={df.columns[0]: 'team_full_name'}, inplace=True)\n",
    "\n",
    "    df = df[~df['team_full_name'].str.contains('Division|Conference', na=False)]\n",
    "\n",
    "    df[df.columns[0]] = df[df.columns[0]].replace({r'\\*': ''}, regex=True)\n",
    "    \n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    df['ranking'] = df.index + 1\n",
    "\n",
    "    df['ranking'] = df['ranking'].astype(int)\n",
    "\n",
    "    df = df[['Season',df.columns[0], 'conference','ranking']]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.basketball-reference.com/leagues/NBA_2024_standings.html\n",
    "\n",
    "def scrape_ranking(season):\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_standings.html\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # print(response)\n",
    "    # print(url)\n",
    "\n",
    "    for conf in ['W','E']:\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            table = soup.find('table', {'id': f\"confs_standings_{conf}\"})\n",
    "\n",
    "            if table:\n",
    "                df = pd.read_html(io.StringIO(str(table)))[0]\n",
    "                \n",
    "                df['Season'] = season\n",
    "                if conf == 'W':\n",
    "                    df[\"conference\"] = \"WEST\" \n",
    "                else:\n",
    "                    df['conference'] = \"EAST\"\n",
    "                    \n",
    "                df = clean_ranking(df)\n",
    "\n",
    "                all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "            else:\n",
    "                print(f\"No table found for {season}. Looking in Division Standings...\")\n",
    "\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                table = soup.find('table', {'id': f\"divs_standings_{conf}\"})\n",
    "\n",
    "                if table:\n",
    "                    df = pd.read_html(io.StringIO(str(table)))[0]\n",
    "                    \n",
    "                    df['Season'] = season\n",
    "                    if conf == 'W':\n",
    "                        df[\"conference\"] = \"WEST\" \n",
    "                    else:\n",
    "                        df['conference'] = \"EAST\"\n",
    "                    \n",
    "                    df = clean_ranking(df)\n",
    "\n",
    "                    all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "                else:\n",
    "                    print(f\"No table found for {season} in Division Standings.\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data for {season}\")\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = scrape_ranking(2007)\n",
    "ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append Number of PO Apperence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_po(df):\n",
    "    df['Season'] = (df['Season'].str[0:2] + df['Season'].str[5:]).astype(int)\n",
    "\n",
    "    df.drop(df.columns[8], axis=1, inplace=True)\n",
    "\n",
    "    df.drop(df.columns[14], axis=1, inplace=True)\n",
    "\n",
    "    df.loc[:, 'Team'] = df['Team'].replace({r'\\*': '', ',': ''}, regex=True)\n",
    "    \n",
    "    df.dropna(subset=['Playoffs'], inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.basketball-reference.com/teams/BOS/\n",
    "\n",
    "def scrape_po(team_names):\n",
    "    all_data = pd.DataFrame()\n",
    "    print('Scraping Playoffs apperences data for every team...')\n",
    "    \n",
    "    for team in team_names:\n",
    "        if team == 'BRK':\n",
    "            team = 'NJN'\n",
    "        elif team == 'CHO':\n",
    "            team = 'CHA'\n",
    "        elif team == 'NOP':\n",
    "            team = 'NOH'\n",
    "            \n",
    "        url = f\"https://www.basketball-reference.com/teams/{team}\"\n",
    "\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # print(response)\n",
    "        # print(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            table = soup.find('table', {'id': team})\n",
    "\n",
    "            if table:\n",
    "                df = pd.read_html(io.StringIO(str(table)))[0]\n",
    "                \n",
    "                df = clean_po(df)\n",
    "\n",
    "                all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "            else:\n",
    "                print(f\"No table found for {team}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data for {team} \")\n",
    "\n",
    "        time.sleep(4)\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "po = scrape_po(team_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_team_name(row):\n",
    "    team_name_mapping = get_team_names(2000)  # get team names from older season\n",
    "    return team_name_mapping.get(row['team_full_name'], row['team_full_name'])  # Map the team name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_po(po):\n",
    "    \n",
    "    po.rename(columns={\"Team\": 'team_full_name'}, inplace=True)\n",
    "\n",
    "    po['team_full_name'] = po.apply(map_team_name, axis=1)    \n",
    "\n",
    "    po = po[['team_full_name', 'Season']]\n",
    "\n",
    "    po_apperences = po.sort_values(by=['team_full_name', 'Season'])  \n",
    "\n",
    "    po_apperences['nb_po_apperence'] = po_apperences.groupby('team_full_name').cumcount() + 1\n",
    "\n",
    "    return po_apperences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "po_apperences = nb_po(po)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po_apperences[po_apperences.team_full_name=='Brooklyn Nets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop for multiple seasons :o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_rosters():\n",
    "    all_rosters = pd.DataFrame()\n",
    "\n",
    "    for season in range(start, end):  \n",
    "        print(f\"Scraping data for the {season-1}-{season} season...\")\n",
    "\n",
    "        roster = scrape_roster(season)\n",
    "\n",
    "        if roster is not None:\n",
    "            all_rosters = pd.concat([all_rosters, roster], ignore_index=True)\n",
    "            \n",
    "    return all_rosters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rosters = scrape_all_rosters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1400,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avg_roster = team_avg_roster(all_rosters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1401,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avg_roster.to_csv(f\"data/temp/{start}_{end-1}_avg_roster.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_preseason_odds():\n",
    "    all_preseason_odds = pd.DataFrame()\n",
    "\n",
    "    for season in range(start, end):  \n",
    "        print(f\"Scraping data for the {season-1}-{season} season...\")\n",
    "\n",
    "        preseason_odds = scrape_preseason_odds(season)\n",
    "\n",
    "        if preseason_odds is not None:\n",
    "            all_preseason_odds = pd.concat([all_preseason_odds, preseason_odds], ignore_index=True)\n",
    "\n",
    "    return all_preseason_odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preseason_odds = scrape_all_preseason_odds()[[\"Team\",\"Odds\"]]\n",
    "\n",
    "all_avg_n_odds = pd.merge(all_avg_roster, all_preseason_odds, left_on='team_full_name', right_on='Team', how='left')\n",
    "\n",
    "all_avg_n_odds.drop(columns='Team', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1404,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avg_n_odds.to_csv(f\"data/temp/{start}_{end-1}_avg_n_odds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_salaries():\n",
    "    all_salaries = pd.DataFrame()\n",
    "\n",
    "    driver = webdriver.Chrome() \n",
    "\n",
    "    for season in range(start, end):  \n",
    "        print(f\"Scraping data for the {season-1}-{season} season...\")\n",
    "\n",
    "        salaries = scrape_salaries(\n",
    "            season,\n",
    "            driver,\n",
    "        )\n",
    "\n",
    "        if salaries is not None:\n",
    "            all_salaries = pd.concat([all_salaries, salaries], ignore_index=True)\n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "    return all_salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_salaries = scrape_all_salaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1407,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_salaries.to_csv(f\"data/temp/{start}_{end-1}_salaries_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_top_players = find_top_players(all_salaries)\n",
    "\n",
    "team_salary_stats = all_salaries.groupby(['team', 'Season']).agg(\n",
    "    highest_salary=('Salary', 'max'),\n",
    "    median_salary=('Salary', 'median'),\n",
    "    total_salary=('Salary', 'sum'),\n",
    "    \n",
    ").reset_index()\n",
    "\n",
    "all_team_salary_stats = pd.merge(team_salary_stats, all_top_players, on=['team', 'Season'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_team_salary_stats.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1410,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avg_odds_salary_players = pd.merge(all_avg_n_odds, all_team_salary_stats,on=['team', 'Season'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avg_odds_salary_players.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_nba_championships(seasons_list):\n",
    "    \n",
    "    all_team_championships = pd.DataFrame()\n",
    "\n",
    "    for season in seasons_list:\n",
    "        team_names = get_team_names(season)\n",
    "\n",
    "        team_championships = nb_championships(season)\n",
    "        \n",
    "        all_team_championships = pd.concat([all_team_championships, team_championships], ignore_index=True)\n",
    "\n",
    "    return all_team_championships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1413,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_team_championships = all_nba_championships(seasons_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1414,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avg_odds_salary_players_champ = all_avg_odds_salary_players.merge(all_team_championships, on=['team', 'Season'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_avg_odds_salary_players[all_avg_odds_salary_players.team=='NOH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_avg_odds_salary_players_champ[all_avg_odds_salary_players_champ.team=='BOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avg_odds_salary_players_champ.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1418,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avg_odds_salary_players_champ.to_csv(f\"data/temp/{start}_{end-1}_avg_odds_salary_players_champ.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_scrape_ranking(seasons_list):\n",
    "    \n",
    "    all_ranking = pd.DataFrame()\n",
    "\n",
    "    for season in seasons_list:\n",
    "        ranking = scrape_ranking(season)\n",
    "        all_ranking = pd.concat([all_ranking, ranking], ignore_index=True)\n",
    "\n",
    "    return all_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ranking = all_scrape_ranking(seasons_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ranking.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avg_odds_salary_players_champ.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_avg_odds_salary_players_champ_rk = all_avg_odds_salary_players_champ.merge(all_ranking, on=['team_full_name', 'Season'], how='left')\n",
    "all_avg_odds_salary_players_champ_rk = all_avg_odds_salary_players_champ.merge(all_ranking, on=['team_full_name', 'Season'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po = scrape_po(team_names)\n",
    "\n",
    "po_apperences = nb_po(po)\n",
    "all_avg_odds_salary_players_champ_rk_po = all_avg_odds_salary_players_champ_rk.merge(po_apperences, on=['team_full_name','Season'],how='left')\n",
    "all_avg_odds_salary_players_champ_rk_po = all_avg_odds_salary_players_champ_rk_po.sort_values(by=['team_full_name', 'Season'], ascending=[True, False])\n",
    "all_avg_odds_salary_players_champ_rk_po['nb_po_apperence'] = all_avg_odds_salary_players_champ_rk_po['nb_po_apperence'].bfill()\n",
    "all_avg_odds_salary_players_champ_rk_po['nb_po_apperence'] = all_avg_odds_salary_players_champ_rk_po['nb_po_apperence'].astype(\"Int64\")\n",
    "\n",
    "\n",
    "all_avg_odds_salary_players_champ_rk_po.insert(16, 'nb_po_apperence', all_avg_odds_salary_players_champ_rk_po.pop('nb_po_apperence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df['ranking'] = final_df['ranking'].astype(\"Int64\")\n",
    "all_avg_odds_salary_players_champ_rk.ranking.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avg_odds_salary_players_champ_rk.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1432,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avg_odds_salary_players_champ_rk_po.to_csv(f\"data/temp/{start}_{end-1}_avg_odds_salary_players_champ_rk_po.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1433,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2013_2025 = pd.read_csv('data/2013_2025_avg_odds_salary_players_champ_rk.csv', index_col=False)\n",
    "df_2010_2012 = pd.read_csv('data/temp/2010_2012_avg_odds_salary_players_champ_rk.csv',  index_col=False)\n",
    "\n",
    "df_2013_2025 = df_2013_2025.iloc[:, 1:]\n",
    "df_2010_2012 = df_2010_2012.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2013_2025.Season.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2010_2012.Season.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1436,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([df_2013_2025, df_2010_2012], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1437,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['ranking'] = final_df['ranking'].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.ranking.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.sort_values(['Season'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1442,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(f\"data/2010_2025_avg_odds_salary_players_champ_rk.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append Conference field to Final Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df['conference'] = final_df['team'].map(team_conferences)\n",
    "\n",
    "# final_df.insert(3, 'conference', final_df.pop('conference'))\n",
    "\n",
    "# final_df.to_csv(f\"data/2020_2025_avg_odds_salary_players_champ_rk.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append Number of Championships in the past 4 years field to Final Df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_championships = []\n",
    "nba_champions = scrape_champions()\n",
    "\n",
    "for i, row in final_df.iterrows():\n",
    "    team = row['team']  \n",
    "    season = row['Season']     \n",
    "\n",
    "    nb_interval = len(nba_champions[\n",
    "        (nba_champions['team'] == team) & \n",
    "        (nba_champions['Year'] <= season) & \n",
    "        (nba_champions['Year'] > season-4)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    nb_past_championships = len(nba_champions[(nba_champions['team'] == team) & \n",
    "                                                (nba_champions['Year'] <= season) & \n",
    "                                                (nba_champions['Year'] > season-4)])\n",
    "    \n",
    "    team_championships.append(nb_past_championships)\n",
    "\n",
    "\n",
    "final_df['nb_champ_past_4y'] = team_championships\n",
    "\n",
    "column_to_move = final_df.pop(\"nb_champ_past_4y\")\n",
    "\n",
    "final_df.insert(15, \"nb_champ_past_4y\", column_to_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.to_csv(f\"data/2015_2025_avg_odds_salary_players_champ_rk.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append Number of Playoff Apperence field to Final Df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv('../data/2008_2025_avg_odds_salary_players_champ_rk.csv',  index_col=False)\n",
    "final_df = final_df.iloc[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po_apperences = nb_po(po)\n",
    "\n",
    "final_df_new = final_df.merge(po_apperences, on=['team_full_name','Season'],how='left')\n",
    "final_df_new = final_df_new.sort_values(by=['team_full_name', 'Season'], ascending=[True, False])\n",
    "final_df_new['nb_po_apperence'] = final_df_new['nb_po_apperence'].bfill()\n",
    "final_df_new['nb_po_apperence'] = final_df_new['nb_po_apperence'].astype(\"Int64\")\n",
    "\n",
    "\n",
    "final_df_new.insert(16, 'nb_po_apperence', final_df_new.pop('nb_po_apperence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_new[final_df_new.team_full_name=='Houston Rockets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_new.to_csv(f\"../data/2008_2025_avg_odds_salary_players_champ_rk.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = f\"https://www.basketball-reference.com/teams/NOH/2013.html\"\n",
    "\n",
    "# response = requests.get(url)\n",
    "\n",
    "# # print(response)\n",
    "# # print(url)\n",
    "\n",
    "# if response.status_code == 200:\n",
    "#     soup = BeautifulSoup(response.content, 'html.parser')\n",
    "#     table = soup.find('table', {'id': 'roster'})\n",
    "\n",
    "#     if table:\n",
    "#         df = pd.read_html(io.StringIO(str(table)))[0]\n",
    "\n",
    "#         df['Season'] = 2013\n",
    "        \n",
    "#         df = clean_roster(df,'NOH')\n",
    "\n",
    "#         all_avg_roster = pd.concat([all_avg_roster, df], ignore_index=True)\n",
    "\n",
    "#     else:\n",
    "    \n",
    "#         print(f\"No table found for 2013\")\n",
    "\n",
    "# else:\n",
    "#     print(f\"Failed to retrieve data for 2013\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = f\"https://www.basketball-reference.com/teams/NOH/2013.html\"\n",
    "\n",
    "# driver = webdriver.Chrome() \n",
    "\n",
    "# driver.get(url)\n",
    "\n",
    "# time.sleep(5)\n",
    "\n",
    "# soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# div = soup.find('div', {'id': 'div_salaries2'})\n",
    "\n",
    "# if div:\n",
    "#     table = div.find('table', {'id': 'salaries2'})\n",
    "#     if table:\n",
    "#         df = pd.read_html(io.StringIO(str(table)))[0]\n",
    "#         df['Season'] = 2013\n",
    "#         df['team']= 'NOH'\n",
    "#         df = clean_salaries(df)\n",
    "\n",
    "#         all_salaries = pd.concat([all_salaries, df], ignore_index=True)\n",
    "\n",
    "#     else:\n",
    "#         print(f\"No table found inside the div for NOH in 2013\")\n",
    "# else:\n",
    "#     print(f\"No div with id 'div_salaries2' found for NOH in 2013\")\n",
    "\n",
    "# driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
